Section 1: Software and platform section
### Software and Platforms Used

* **Primary Software:**
  Python, executed within Jupyter and Google Colab notebooks.

* **Required Packages:**
  The following Python libraries were imported and used for analysis and visualization:

  ```python
  import requests
  import xml.etree.ElementTree as ET
  from bs4 import BeautifulSoup
  import json
  import pandas as pd
  import re
  import matplotlib.pyplot as plt
  import seaborn as sns
  ```

* **Platforms:**
  The project was conducted on both **Windows** and **Mac** operating systems.


Section 2: A Map of Documentation
asian_recipe_classifier_ds4002/
│
├── Data/
│   ├── Top_15_Ingredients_per_Country.csv
│   ├── Top_50_Foods_with_Dominant_Country.csv
│   └── asianrecipesfinal.csv
│
├── Scripts/
|   └── asian_recipe_modeling.ipynb
|   └── ingredients.ipynb
│
├── Output/
│   ├── distofingredients.png
│   ├── ingredientcountdist.png
│   ├── numrecipes.png
│   ├── top20.png
│   ├── top50.png
│   └── uniqueingredient.png
│
├── LICENSE.md
├── README.md
└── Research Question and Approach

Section 3: Instructions for Reproducing the Results
Follow these steps to regenerate all figures in Output/ from the CSVs in Data/ using the notebook in Scripts/.
0) Prerequisites
Python 3.9 or newer

Git

(Recommended) A clean virtual environment

No web scraping is required; all needed CSVs are already in Data/.

1) Clone the repository
git clone https://github.com/<your-username>/asian_recipe_classifier_ds4002.git
cd asian_recipe_classifier_ds4002

2) Create & activate a virtual environment
macOS/Linux:
python3 -m venv .venv
source .venv/bin/activate

Windows (PowerShell):
python -m venv .venv
.\.venv\Scripts\Activate.ps1

3) Install dependencies
If you have a requirements.txt in the repo, run:
pip install -r requirements.txt

Otherwise install the minimal set:
pip install pandas matplotlib seaborn beautifulsoup4 lxml requests jupyter

4) Verify project structure
Your working directory should contain:
Data/   Scripts/   Output/   LICENSE.md   README.md

and inside Scripts/ the notebook:
ingredients.ipynb

5) Run the analysis notebook
Option A — Jupyter (interactive, local):
jupyter notebook

Open Scripts/ingredients.ipynb and choose Kernel → Restart & Run All.
 All figures will be written to Output/ automatically.
Option B — Command line (non-interactive, reproducible):
jupyter nbconvert --execute \
  --to notebook \
  --output Output/ingredients_executed.ipynb \
  Scripts/ingredients.ipynb

This executes the notebook headlessly and saves an executed copy to Output/. Plots generated by the notebook code will also be saved into Output/.
Option C — Google Colab:
Upload or open the repo from GitHub in Colab.


Ensure the runtime working directory contains the Data/ folder (so relative paths resolve).


Open Scripts/ingredients.ipynb → Runtime → Run all.


6) Expected outputs
After a successful run, Output/ will contain (overwriting if present):
distofingredients.png


ingredientcountdist.png


numrecipes.png


top20.png


top50.png


uniqueingredient.png


7) Re-running from a clean slate (optional)
Remove prior figures, then re-run Step 5.
 macOS/Linux:
rm -f Output/*.png Output/ingredients_executed.ipynb

Windows (PowerShell):
Remove-Item Output\*.png, Output\ingredients_executed.ipynb -ErrorAction Ignore

8) Troubleshooting
File not found (CSV): Confirm you are in the repo root and the Data/ folder contains:
 Top_15_Ingredients_per_Country.csv, Top_50_Foods_with_Dominant_Country.csv,
 asian_recipes_one_row.csv, asianrecipesfinal.csv.


ImportError: Re-run Step 3 to install missing packages.


Plots not saving: Make sure you ran Restart & Run All and that the notebook’s save paths point to Output/.


Colab path issues: Mount Drive or clone the repo in /content, then keep the relative paths unchanged.


Matplotlib display errors (locally): Add %matplotlib inline near the top of the notebook before plotting.


Note: If you later add a modeling notebook (e.g., asian_recipe_modeling.ipynb), run it after ingredients.ipynb using the same steps so it can reuse the cleaned/derived data.


